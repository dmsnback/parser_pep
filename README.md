<a name="Начало"></a>

# Асинхронный парсер PEP 

Асинхронный парсер официальной документации Python и документов PEP на базе фреймворка Scrapy.
 
- [Технологии](#Технологии)
 - [Описание](#Описание)
 - [Запуск парсера](#Запуск)
 - [Автор](#Автор)

#
<a name="Технологии"></a>

### Технологии
[![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)](https://www.python.org)


#
<a name="Описание"></a>

### Описание

Парсер выводит собранную информацию в два файла формата ```.csv```.

- В первый файл выводится список всех PEP: номер, название и статус

- Второй файл содержит сводку по статусам PEP:
  * Сколько найдено документов в каждом статусе (статус, количество). 
  * В последней строке этого файла стоит общее количество всех документов.

Скачанная информация сохраняется в папке ```results ``` с указанием даты и времени.

#
<a name="Запуск"></a>

### Запуск парсера

- Склонируйте репозиторий

```python
git clone git@github.com:dmsnback/scrapy_parser_pep.git
```

- Установите и активируйте виртуальное окружение
```python
python3 -m venv venv
```
Для ```Windows```
```python
source venv/Scripts/activate
```
Для ```Mac/Linux```
```python
source venv/bin/activate
```
- Установите зависимости из файла ```requirements.txt```
```python
pip install -r requirements.txt
```
- Парсер запускается через терминал. 
```python
scrapy crawl pep
```
#
<a name="Автор"></a>

### Автор

- [Титенков Дмитрий](https://github.com/dmsnback)

[Вернуться в начало](#Начало)